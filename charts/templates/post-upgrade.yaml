{{ if .Values.restart_ovs }}
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ovs-ovn-upgrade
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.k8s.io/system-only: "true"
  name: system:ovs-ovn-upgrade
rules:
  - apiGroups:
      - apps
    resources:
      - daemonsets
    resourceNames:
      - ovs-ovn
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
      - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ovs-ovn-upgrade
roleRef:
  name: system:ovs-ovn-upgrade
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
subjects:
  - kind: ServiceAccount
    name: ovs-ovn-upgrade
    namespace: kube-system
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Chart.Name }}"
  namespace: kube-system
  labels:
    app.kubernetes.io/managed-by: {{ .Release.Service | quote }}
    app.kubernetes.io/instance: {{ .Release.Name | quote }}
    app.kubernetes.io/version: {{ .Chart.AppVersion }}
    helm.sh/chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": post-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  completions: 1
  template:
    metadata:
      name: "{{ .Release.Name }}"
      labels:
        app.kubernetes.io/managed-by: {{ .Release.Service | quote }}
        app.kubernetes.io/instance: {{ .Release.Name | quote }}
        helm.sh/chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
        app: post-upgrade
        component: job
    spec:
      tolerations:
        - key: ""
          operator: "Exists"
          effect: "NoSchedule"
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: kubernetes.io/hostname
              labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - post-upgrade
                  - key: component
                    operator: In
                    values:
                      - job
      restartPolicy: Never
      hostNetwork: true
      nodeSelector:
        kubernetes.io/os: "linux"
      serviceAccount: ovs-ovn-upgrade
      serviceAccountName: ovs-ovn-upgrade
      containers:
        - name: post-upgrade-job
          image: "{{ .Values.global.registry.address}}/{{ .Values.global.images.kubeovn.repository }}:{{ .Values.global.images.kubeovn.tag }}"
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          command:
            - sh
            - -c
            - /kube-ovn/upgrade-ovs.sh 2>&1 | tee -a /var/log/kube-ovn/upgrade-ovs.log
          volumeMounts:
            - mountPath: /var/log/kube-ovn
              name: kube-ovn-log
      volumes:
        - name: kube-ovn-log
          hostPath:
            path: /var/log/kube-ovn
{{ end }}
